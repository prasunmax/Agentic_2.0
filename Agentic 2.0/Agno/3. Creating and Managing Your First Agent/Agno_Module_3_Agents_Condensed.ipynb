{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fb30aeb",
   "metadata": {},
   "source": [
    "\n",
    "# Module 3 — **Agents** \n",
    "**Goal:** A compact, teachable reference that mirrors the official docs for Agno Agents and the core subtopics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8b751e",
   "metadata": {},
   "source": [
    "\n",
    "## 0) Agents — What & Why (Quick Overview)\n",
    "\n",
    "**Agents are AI programs where a language model controls the flow of execution.**  \n",
    "Core loop = **Model** (decides) + **Instructions** (behavior) + **Tools** (actions). They can also use **Memory**, **Storage**, **Knowledge (Agentic RAG)**, and **Reasoning**.\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    subgraph Agent\n",
    "        I[Instructions] --> M[(Model)]\n",
    "        M -->|think/plan| R[Reasoning]\n",
    "        M -->|call| T[Tools]\n",
    "        M -->|respond| O[Output]\n",
    "        MEM[(Memory/Session)] --> M\n",
    "        KN[(Knowledge RAG)] --> M\n",
    "    end\n",
    "    ST[(Storage/DB)] --- MEM\n",
    "    \n",
    "    style I fill:#e1f5fe\n",
    "    style M fill:#fff3e0\n",
    "    style R fill:#f3e5f5\n",
    "    style T fill:#e8f5e8\n",
    "    style O fill:#e8f5e8\n",
    "    style MEM fill:#e3f2fd\n",
    "    style KN fill:#e3f2fd\n",
    "    style ST fill:#e3f2fd\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842e355d",
   "metadata": {},
   "source": [
    "\n",
    "### Guide Map (where each topic fits)\n",
    "\n",
    "| Topic | You learn to… |\n",
    "|---|---|\n",
    "| **Building Agents** | Assemble model + tools + instructions; minimal agent |\n",
    "| **Running Agents** | Use `run()`, async/streaming, events, user/session |\n",
    "| **Debugging** | Enable debug mode; CLI app; inspect flows |\n",
    "| **Sessions** | Multi‑turn threads, summaries, history, storage flags |\n",
    "| **Input & Output** | Strings, structured I/O with Pydantic, parser/output models |\n",
    "| **Context** | Build system/user messages; few-shot; caching |\n",
    "| **Dependencies** | Inject variables/functions into context dynamically |\n",
    "| **Agent State** | Persist `session_state`; agentic state tool |\n",
    "| **Memory** | User memories; agent-managed updates |\n",
    "| **Knowledge** | Agentic RAG (search at runtime) |\n",
    "| **Tools** | Toolkits, custom tools, MCP |\n",
    "| **Multimodal** | Images/audio/video/files in & out |\n",
    "| **Hooks** | Pre-/Post- validation & transforms |\n",
    "| **Metrics** | Tokens, timing, per-run/session stats |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec5f0f9",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Building Agents (start small → layer features)\n",
    "\n",
    "Start with **model + tools + instructions** and iterate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b390b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal \"report\" agent (use after setting provider creds)\n",
    "from agno.agent import Agent\n",
    "from agno.models.anthropic import Claude\n",
    "from agno.tools.hackernews import HackerNewsTools\n",
    "\n",
    "agent = Agent(\n",
    "    model=Claude(id=\"claude-sonnet-4-5\"),\n",
    "    tools=[HackerNewsTools()],\n",
    "    instructions=\"Write a report on the topic. Output only the report.\",\n",
    "    markdown=True,\n",
    ")\n",
    "agent.print_response(\"Trending startups and products.\", stream=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a29d7e",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Running Agents (the loop)\n",
    "\n",
    "**Run loop (concept):** build context → call model → (maybe) tool call → update context → repeat → final message.\n",
    "\n",
    "```mermaid\n",
    "sequenceDiagram\n",
    "  participant You\n",
    "  participant A as Agent\n",
    "  participant M as Model\n",
    "  participant T as Tools\n",
    "  You->>A: run(input)\n",
    "  A->>M: context (system, user, history, memories, state, deps)\n",
    "  M-->>A: message or tool call\n",
    "  alt tool call\n",
    "    A->>T: execute(tool, args)\n",
    "    T-->>A: result\n",
    "    A->>M: updated context (with tool result)\n",
    "  end\n",
    "  M-->>A: final message\n",
    "  A-->>You: RunOutput / stream\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blocking vs streaming (reference)\n",
    "from typing import Iterator\n",
    "from agno.agent import Agent, RunOutput, RunOutputEvent, RunEvent\n",
    "from agno.models.anthropic import Claude\n",
    "from agno.tools.hackernews import HackerNewsTools\n",
    "from agno.utils.pprint import pprint_run_response\n",
    "\n",
    "agent = Agent(\n",
    "    model=Claude(id=\"claude-sonnet-4-5\"),\n",
    "    tools=[HackerNewsTools()],\n",
    "    instructions=\"Write a report on the topic. Output only the report.\",\n",
    "    markdown=True,\n",
    ")\n",
    "\n",
    "# Blocking\n",
    "response: RunOutput = agent.run(\"Trending startups and products.\")\n",
    "print(response.content)\n",
    "\n",
    "# Streaming (content chunks)\n",
    "stream: Iterator[RunOutputEvent] = agent.run(\"Trending products\", stream=True)\n",
    "for chunk in stream:\n",
    "    if chunk.event == RunEvent.run_content:\n",
    "        print(chunk.content)\n",
    "\n",
    "# Pretty-print stream\n",
    "stream = agent.run(\"Trending products\", stream=True)\n",
    "pprint_run_response(stream, markdown=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5fb225",
   "metadata": {},
   "source": [
    "\n",
    "### Streaming & Events (cheatsheet)\n",
    "\n",
    "Enable `stream=True` to get an iterator of `RunOutputEvent`. Add `stream_events=True` for **all events** (tool calls, reasoning, etc.).\n",
    "\n",
    "| Category | Event Types (key ones) |\n",
    "|---|---|\n",
    "| **Core** | `RunStarted`, `RunContent`, `RunContentCompleted`, `RunCompleted`, `RunError`, `RunCancelled` |\n",
    "| **Control** | `RunPaused`, `RunContinued` |\n",
    "| **Tools** | `ToolCallStarted`, `ToolCallCompleted` |\n",
    "| **Reasoning** | `ReasoningStarted`, `ReasoningStep`, `ReasoningCompleted` |\n",
    "| **Memory** | `MemoryUpdateStarted`, `MemoryUpdateCompleted` |\n",
    "| **Session Summary** | `SessionSummaryStarted`, `SessionSummaryCompleted` |\n",
    "| **Hooks** | `PreHookStarted/Completed`, `PostHookStarted/Completed` |\n",
    "| **Parser/Output Models** | `ParserModelResponse*`, `OutputModelResponse*` |\n",
    "\n",
    "You can also define **custom events** by subclassing `CustomEvent` and `yield`ing them from tools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ba6a04",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Debugging Agents\n",
    "\n",
    "* Set `debug_mode=True` (agent-wide) or on a specific `run()` call.  \n",
    "* Use `debug_level=2` for extra detail.  \n",
    "* Try the built-in **interactive CLI** with `agent.cli_app(stream=True)` during development.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feae43f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.models.anthropic import Claude\n",
    "from agno.tools.hackernews import HackerNewsTools\n",
    "\n",
    "agent = Agent(\n",
    "    model=Claude(id=\"claude-sonnet-4-5\"),\n",
    "    tools=[HackerNewsTools()],\n",
    "    instructions=\"Write a report on the topic. Output only the report.\",\n",
    "    markdown=True,\n",
    "    debug_mode=True,\n",
    "    # debug_level=2,\n",
    ")\n",
    "\n",
    "# Terminal debug output\n",
    "agent.print_response(\"Trending startups and products.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8e37a4",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Agent Sessions (multi‑turn + persistence)\n",
    "\n",
    "**Concepts:** `session_id` (thread), `run_id` (turn), **messages** (model <-> agent protocol).\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    U[User] -->|run| A[Agent]\n",
    "    A -->|persist| DB[(DB Storage)]\n",
    "    subgraph DB\n",
    "        S1[Session: id=S-1]\n",
    "        S2[Session: id=S-2]\n",
    "    end\n",
    "    S1 --- R1[Run r-101]\n",
    "    S1 --- R2[Run r-102]\n",
    "    S2 --- R3[Run r-201]\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11284794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single session (ids are auto if not provided)\n",
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "\n",
    "agent = Agent(model=OpenAIChat(id=\"gpt-5-mini\"))\n",
    "resp = agent.run(\"Tell me a 5 second short story about a robot\")\n",
    "print(resp.content, resp.run_id, resp.session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a303c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-user / multi-session (with SQLite persistence)\n",
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.db.sqlite import SqliteDb\n",
    "\n",
    "db = SqliteDb(db_file=\"tmp/data.db\")\n",
    "agent = Agent(model=OpenAIChat(id=\"gpt-5-mini\"), db=db, add_history_to_context=True, num_history_runs=3)\n",
    "\n",
    "u1, s1 = \"user_101\", \"session_101\"\n",
    "u2, s2 = \"user_102\", \"session_102\"\n",
    "\n",
    "agent.print_response(\"Tell me a 5 second short story about a robot.\", user_id=u1, session_id=s1)\n",
    "agent.print_response(\"Now tell me a joke.\", user_id=u1, session_id=s1)\n",
    "agent.print_response(\"Tell me about quantum physics.\", user_id=u2, session_id=s2)\n",
    "agent.print_response(\"What is the speed of light?\", user_id=u2, session_id=s2)\n",
    "agent.print_response(\"Give me a summary of our conversation.\", user_id=u1, session_id=s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972e83ce",
   "metadata": {},
   "source": [
    "\n",
    "### Session Summaries & History Controls\n",
    "\n",
    "* Set `enable_session_summaries=True` to auto‑maintain summaries (customize with `SessionSummaryManager`).  \n",
    "* Add history to context with `add_history_to_context=True` and **optionally** `num_history_runs`.  \n",
    "* Limit history **tool calls** using `max_tool_calls_from_history=n`.  \n",
    "* Control storage footprint with: `store_media`, `store_tool_messages`, `store_history_messages`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7bfc0c",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Input & Output (Strings → Structured Data)\n",
    "\n",
    "Default: **string in → string out**. For reliability, use **Pydantic** schemas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193b3aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structured OUTPUT example\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "\n",
    "class MovieScript(BaseModel):\n",
    "    setting: str = Field(..., description=\"Setting for a blockbuster\")\n",
    "    ending: str = Field(..., description=\"Provide a happy ending if absent\")\n",
    "    genre: str = Field(..., description=\"Pick action/thriller/romcom if unknown\")\n",
    "    name: str\n",
    "    characters: List[str]\n",
    "    storyline: str\n",
    "\n",
    "structured_output_agent = Agent(\n",
    "    model=OpenAIChat(id=\"gpt-5-mini\"),\n",
    "    description=\"You write movie scripts.\",\n",
    "    output_schema=MovieScript,\n",
    ")\n",
    "structured_output_agent.print_response(\"New York\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850a6ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structured INPUT + Validation\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.tools.hackernews import HackerNewsTools\n",
    "\n",
    "class ResearchTopic(BaseModel):\n",
    "    topic: str\n",
    "    focus_areas: List[str] = Field(description=\"Specific areas to focus on\")\n",
    "    target_audience: str = Field(description=\"Who this research is for\")\n",
    "    sources_required: int = Field(default=5)\n",
    "\n",
    "hackernews_agent = Agent(\n",
    "    name=\"Hackernews Agent\",\n",
    "    model=OpenAIChat(id=\"gpt-5-mini\"),\n",
    "    tools=[HackerNewsTools()],\n",
    "    role=\"Extract key insights and content from Hackernews posts\",\n",
    "    input_schema=ResearchTopic,  # optional: enforce\n",
    ")\n",
    "\n",
    "hackernews_agent.print_response(\n",
    "    input={\"topic\": \"AI\", \"focus_areas\": [\"AI\",\"ML\"], \"target_audience\":\"Developers\", \"sources_required\": \"5\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23e376f",
   "metadata": {},
   "source": [
    "\n",
    "**Typesafe agents** = set **both** `input_schema` and `output_schema`.  \n",
    "You can also improve formatting with a **parser model** or choose a distinct **output model** for the final response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39672fda",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Context Engineering (system + user messages)\n",
    "\n",
    "**System message** = description + instructions + flags (markdown, time, name, location, memories, summary, session state, knowledge filters).\n",
    "\n",
    "```mermaid\n",
    "flowchart TB\n",
    "  D[Description]-->SYS\n",
    "  INS[Instructions]-->SYS\n",
    "  FLAGS[Add-ons: time, name, location,<br/>memories, summary, state, filters]-->SYS\n",
    "  EX[Additional Context / Few-shot]-->SYS\n",
    "  SYS[System Message]-->CTX[Final Context]\n",
    "  UM[User Message]-->CTX\n",
    "  HIST[Chat History]-->CTX\n",
    "  DEPS[Dependencies]-->UM\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5c1360",
   "metadata": {},
   "source": [
    "\n",
    "### System Message Parameters (high-value subset)\n",
    "\n",
    "| Param | Purpose |\n",
    "|---|---|\n",
    "| `description`, `instructions`, `expected_output` | Core behavior / output format |\n",
    "| `markdown` | Ask model to format in Markdown |\n",
    "| `add_datetime_to_context`, `add_name_to_context`, `add_location_to_context` | Temporal/identity/location awareness |\n",
    "| `add_session_summary_to_context`, `add_memories_to_context`, `add_session_state_to_context` | Persisted context |\n",
    "| `enable_agentic_knowledge_filters` | Let model choose filters for KB search |\n",
    "| `system_message` | Override entirely |\n",
    "| `build_context=False` | Disable automatic context building when needed |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462a3752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly set/override the system message\n",
    "from agno.agent import Agent\n",
    "agent = Agent(system_message=\"Share a 2 sentence story about love in 12000 CE.\")\n",
    "agent.print_response(\"Begin!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dbe338",
   "metadata": {},
   "source": [
    "\n",
    "**Additional user message context**: set `add_knowledge_to_context` and/or `add_dependencies_to_context=True`.  \n",
    "**Few-shot**: pass `additional_input=[Message(...), ...]`.  \n",
    "**Context caching**: keep static stuff at the top of the system message (provider-dependent).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcdb53c",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Dependencies (dynamic injection)\n",
    "\n",
    "Inject variables/functions into context; reference as `{name}` in instructions or attach the dict to the user message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f936d4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static dep + function dep + add to user message\n",
    "import json, httpx\n",
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "\n",
    "def get_user_profile() -> str:\n",
    "    return json.dumps({\"name\":\"John Doe\",\"experience_level\":\"senior\"}, indent=2)\n",
    "\n",
    "agent = Agent(\n",
    "    model=OpenAIChat(id=\"gpt-5-mini\"),\n",
    "    dependencies={\"user_profile\": get_user_profile, \"plan\":\"gold\"},\n",
    "    add_dependencies_to_context=True,\n",
    "    instructions=\"You are a support agent for plan {plan}.\",\n",
    "    markdown=True,\n",
    ")\n",
    "agent.print_response(\"Summarize my profile and suggest next steps.\", stream=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3235b3f",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Agent State (session_state)\n",
    "\n",
    "Maintain per‑session variables (lists, counters, user fields). Update in tools, expose in instructions, and persist via DB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5cf242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shopping list state with tools\n",
    "from textwrap import dedent\n",
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.db.sqlite import SqliteDb\n",
    "\n",
    "def add_item(session_state, item: str) -> str:\n",
    "    session_state[\"shopping_list\"].append(item)\n",
    "    return f\"Added '{item}' -> {session_state['shopping_list']}\"\n",
    "\n",
    "def list_items(session_state) -> str:\n",
    "    return f\"Current: {session_state['shopping_list'] or 'empty'}\"\n",
    "\n",
    "agent = Agent(\n",
    "    model=OpenAIChat(id=\"gpt-5-mini\"),\n",
    "    session_state={\"shopping_list\": []},\n",
    "    db=SqliteDb(db_file=\"tmp/example.db\"),\n",
    "    tools=[add_item, list_items],\n",
    "    instructions=dedent(\"\"\"\n",
    "      Manage a shopping list. Current: {shopping_list}\n",
    "    \"\"\"),\n",
    "    markdown=True,\n",
    ")\n",
    "agent.print_response(\"Add milk and eggs\", stream=True)\n",
    "print(agent.get_session_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0234a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agentic session state (auto-manage tool)\n",
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.db.sqlite import SqliteDb\n",
    "\n",
    "agent = Agent(\n",
    "    db=SqliteDb(db_file=\"tmp/agents.db\"),\n",
    "    model=OpenAIChat(id=\"gpt-5-mini\"),\n",
    "    session_state={\"shopping_list\": []},\n",
    "    add_session_state_to_context=True,\n",
    "    enable_agentic_state=True,\n",
    ")\n",
    "agent.print_response(\"Add bread and apples\", stream=True)\n",
    "print(agent.get_session_state())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dad48c",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Memory (user personalization)\n",
    "\n",
    "Let agents **remember user facts**. Either give a tool (`enable_agentic_memory`) or auto‑run a manager (`enable_user_memories`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfca697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory (Postgres example — adjust creds before running)\n",
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.db.postgres import PostgresDb\n",
    "from rich.pretty import pprint\n",
    "\n",
    "user_id = \"ava\"\n",
    "db = PostgresDb(db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\", memory_table=\"user_memories\")\n",
    "\n",
    "memory_agent = Agent(\n",
    "    model=OpenAIChat(id=\"gpt-4.1\"),\n",
    "    db=db,\n",
    "    enable_agentic_memory=True,   # or: enable_user_memories=True\n",
    "    markdown=True,\n",
    ")\n",
    "\n",
    "db.clear_memories()\n",
    "\n",
    "memory_agent.print_response(\"My name is Ava and I like to ski.\", user_id=user_id, stream=True, stream_events=True)\n",
    "print(\"Memories about Ava:\"); pprint(memory_agent.get_user_memories(user_id=user_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f3d750",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Knowledge (Agentic RAG)\n",
    "\n",
    "Provide a **Knowledge** base (contents DB + vector DB). Agent searches at runtime (dynamic few‑shot).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348517e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agentic RAG sketch (requires Postgres/pgvector setup)\n",
    "import asyncio\n",
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.knowledge.knowledge import Knowledge\n",
    "from agno.vectordb.pgvector import PgVector\n",
    "from agno.db.postgres.postgres import PostgresDb\n",
    "\n",
    "db_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n",
    "\n",
    "db = PostgresDb(db_url=db_url, knowledge_table=\"knowledge_contents\")\n",
    "knowledge = Knowledge(\n",
    "    contents_db=db,\n",
    "    vector_db=PgVector(table_name=\"recipes\", db_url=db_url),\n",
    ")\n",
    "\n",
    "agent = Agent(model=OpenAIChat(id=\"gpt-5-mini\"), db=db, knowledge=knowledge, markdown=True)\n",
    "\n",
    "async def setup_and_run():\n",
    "    await knowledge.add_content_async(\n",
    "        name=\"Recipes\",\n",
    "        url=\"https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\",\n",
    "        metadata={\"user_tag\": \"Recipes from website\"},\n",
    "    )\n",
    "    await agent.aprint_response(\"How do I make chicken and galangal in coconut milk soup?\", markdown=True)\n",
    "\n",
    "# asyncio.run(setup_and_run())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1f2802",
   "metadata": {},
   "source": [
    "\n",
    "## 11) Tools (toolkits • custom • MCP)\n",
    "\n",
    "Add pre‑built **toolkits** or simple Python functions. You can also connect **MCP** servers for standard tool access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6cbd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toolkit: DuckDuckGo\n",
    "from agno.agent import Agent\n",
    "from agno.tools.duckduckgo import DuckDuckGoTools\n",
    "\n",
    "agent = Agent(tools=[DuckDuckGoTools()], markdown=True)\n",
    "agent.print_response(\"What's happening in France?\", stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80341bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom tool: top HN stories\n",
    "import json, httpx\n",
    "from agno.agent import Agent\n",
    "\n",
    "def get_top_hackernews_stories(num_stories: int = 5) -> str:\n",
    "    ids = httpx.get('https://hacker-news.firebaseio.com/v0/topstories.json').json()\n",
    "    stories = []\n",
    "    for sid in ids[:num_stories]:\n",
    "        s = httpx.get(f'https://hacker-news.firebaseio.com/v0/item/{sid}.json').json()\n",
    "        s.pop(\"text\", None)\n",
    "        stories.append(s)\n",
    "    return json.dumps(stories)\n",
    "\n",
    "agent = Agent(tools=[get_top_hackernews_stories], markdown=True)\n",
    "agent.print_response(\"Summarize the top 5 stories on Hacker News.\", stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f0fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCP tools (async sketch)\n",
    "# from agno.tools.mcp import MCPTools\n",
    "# mcp_tools = MCPTools(command=\"uvx mcp-server-git\")\n",
    "# await mcp_tools.connect()\n",
    "# agent = Agent(tools=[mcp_tools], markdown=True)\n",
    "# await agent.aprint_response(\"What is the license for this project?\", stream=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031cf90d",
   "metadata": {},
   "source": [
    "\n",
    "## 12) Multimodal Agents\n",
    "\n",
    "Inputs & outputs can be text, images, audio, video, files (provider-dependent).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdd99f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image input + web search\n",
    "from agno.agent import Agent\n",
    "from agno.media import Image\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.tools.duckduckgo import DuckDuckGoTools\n",
    "\n",
    "img_agent = Agent(model=OpenAIChat(id=\"gpt-5-mini\"), tools=[DuckDuckGoTools()], markdown=True)\n",
    "img_agent.print_response(\n",
    "    \"Tell me about this image and give me the latest news about it.\",\n",
    "    images=[Image(url=\"https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg\")],\n",
    "    stream=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdca21d",
   "metadata": {},
   "source": [
    "\n",
    "## 13) Pre‑hooks & Post‑hooks\n",
    "\n",
    "Use hooks to **validate** or **transform** inputs/outputs (guardrails, compliance, sanitization, formatting).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e097f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-hook example (length check)\n",
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "from agno.exceptions import CheckTrigger, InputCheckError\n",
    "from agno.run.agent import RunInput, AgentSession\n",
    "\n",
    "def validate_input_length(\n",
    "    run_input: RunInput,\n",
    "    session: AgentSession,\n",
    "    user_id: str | None = None,\n",
    "    debug_mode: bool | None = None,\n",
    ") -> None:\n",
    "    if len(run_input.input_content) > 1000:\n",
    "        raise InputCheckError(\"Input too long. Max 1000 chars\", check_trigger=CheckTrigger.INPUT_NOT_ALLOWED)\n",
    "\n",
    "agent = Agent(model=OpenAIChat(id=\"gpt-5-mini\"), pre_hooks=[validate_input_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b226d386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-hook example (output length)\n",
    "from agno.exceptions import CheckTrigger, OutputCheckError\n",
    "from agno.run.agent import RunOutput\n",
    "\n",
    "def validate_output_length(run_output: RunOutput) -> None:\n",
    "    if len(run_output.content or \"\") > 1000:\n",
    "        raise OutputCheckError(\"Output too long. Max 1000 chars\", check_trigger=CheckTrigger.OUTPUT_NOT_ALLOWED)\n",
    "\n",
    "agent = Agent(model=OpenAIChat(id=\"gpt-5-mini\"), post_hooks=[validate_output_length])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11db4ed9",
   "metadata": {},
   "source": [
    "\n",
    "## 14) Metrics (runs • messages • sessions)\n",
    "\n",
    "Every `RunOutput` includes **metrics**. Sessions aggregate them.\n",
    "\n",
    "| Key fields | Meaning |\n",
    "|---|---|\n",
    "| `input_tokens`, `output_tokens`, `total_tokens` | Text token accounting |\n",
    "| `audio_*_tokens` | Audio token accounting |\n",
    "| `cache_read_tokens`, `cache_write_tokens` | Prompt caching usage |\n",
    "| `reasoning_tokens` | Reasoning‑token budget used |\n",
    "| `duration`, `time_to_first_token` | Latency & UX |\n",
    "| `provider_metrics` | Backend-specific details |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7492f09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics access (sketch)\n",
    "from agno.agent import Agent\n",
    "from agno.models.google import Gemini\n",
    "from agno.tools.duckduckgo import DuckDuckGoTools\n",
    "from agno.db.sqlite import SqliteDb\n",
    "from rich.pretty import pprint\n",
    "\n",
    "agent = Agent(\n",
    "    model=Gemini(id=\"gemini-2.5-flash\"),\n",
    "    tools=[DuckDuckGoTools()],\n",
    "    db=SqliteDb(db_file=\"tmp/agents.db\"),\n",
    "    markdown=True,\n",
    ")\n",
    "run_response = agent.run(\"What is current news in the world?\")\n",
    "\n",
    "# Per message\n",
    "if run_response.messages:\n",
    "    for message in run_response.messages:\n",
    "        if message.role == \"assistant\":\n",
    "            pprint({\"metrics\": message.metrics.to_dict()})\n",
    "\n",
    "# Aggregates\n",
    "pprint({\"run_metrics\": run_response.metrics.to_dict()})\n",
    "pprint({\"session_metrics\": agent.get_session_metrics().to_dict()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4f6e0e",
   "metadata": {},
   "source": [
    "\n",
    "## 15) Quick Checklists\n",
    "\n",
    "**Before your first run**\n",
    "- [ ] Provider SDK + API key configured  \n",
    "- [ ] Minimal agent (model + instructions) works  \n",
    "- [ ] Add one tool; confirm tool calls\n",
    "\n",
    "**When adding reliability**\n",
    "- [ ] `output_schema` defined & validated  \n",
    "- [ ] `debug_mode=True` during dev  \n",
    "- [ ] Add pre/post hooks for validation\n",
    "\n",
    "**When adding persistence & personalization**\n",
    "- [ ] DB storage set on agent  \n",
    "- [ ] `user_id`/`session_id` used appropriately  \n",
    "- [ ] `add_history_to_context` + `num_history_runs` set\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
