{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21d56e21",
   "metadata": {},
   "source": [
    "\n",
    "# Agno Teams — Concepts, Flows & Operations (with Mermaid)\n",
    "\n",
    "*Updated:* 2025-10-25 20:58 UTC  \n",
    "This notebook explains **Agno Teams** from fundamentals to advanced operations.  \n",
    "Diagrams are written in **Mermaid** so you can render them in environments that support it.\n",
    "\n",
    "**Scope covered:** Teams ▸ Building ▸ Running ▸ Delegation ▸ Debugging ▸ Conversation History ▸ Team Sessions ▸ Context Engineering ▸ Input & Output ▸ Dependencies ▸ Shared State ▸ Storage ▸ Memory ▸ Knowledge ▸ Pre/Post‑hooks ▸ Guardrails ▸ Metrics ▸ Cancelling a Run ▸ Custom Loggers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07a55b7",
   "metadata": {},
   "source": [
    "\n",
    "## 1. What is a Team?\n",
    "\n",
    "A **Team** is a coordinator (team leader) plus a set of **members** (Agents or sub‑Teams).  \n",
    "The leader routes work, gathers the results, and returns a single, coherent answer (unless configured to return member replies directly).\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    U[User Input] --> L[Team Leader]\n",
    "    subgraph T[Team]\n",
    "      L -->|delegates| A1[Agent: News]\n",
    "      L -->|delegates| A2[Agent: Weather]\n",
    "      L -->|delegates| S1[Sub‑Team]\n",
    "      subgraph S1[Sub‑Team: Research]\n",
    "        R1[Agent: Web] --> R2[Agent: Summary]\n",
    "      end\n",
    "    end\n",
    "    A1 --> L\n",
    "    A2 --> L\n",
    "    S1 --> L\n",
    "    L --> O[Final Response]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f1d049",
   "metadata": {},
   "source": [
    "\n",
    "### Core Capabilities (Quick Map)\n",
    "\n",
    "| Capability | What it controls | Typical flag(s) / knobs |\n",
    "|---|---|---|\n",
    "| Model | LLM used by leader (and optionally members) | `model` on Team/Agent |\n",
    "| Instructions | How the leader should behave | `instructions`, `description`, `expected_output` |\n",
    "| Tools | Functions/APIs available | `tools` (team or member) |\n",
    "| Delegation | Whether/how to delegate | `respond_directly`, `delegate_task_to_all_members`, `determine_input_for_members` |\n",
    "| History | Past turns in context | `db`, `add_history_to_context`, `num_history_runs` |\n",
    "| Memory | Long‑lived user facts | `enable_user_memories` |\n",
    "| Knowledge | Retrieval‑augmented grounding | `add_knowledge_to_context`, KB tooling |\n",
    "| State | Shared mutable data per session | `session_state`, `enable_agentic_state` |\n",
    "| Debugging | Rich traces & events | `debug_mode`, `debug_level`, streaming events |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6fc606",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Building a Team (minimal)\n",
    "\n",
    "Keep it simple: leader model, a couple of focused members, and a short instruction.\n",
    "\n",
    "```python\n",
    "# (illustrative) minimal setup — adapt IDs to your environment\n",
    "from agno.team import Team\n",
    "from agno.agent import Agent\n",
    "from agno.models.openai import OpenAIChat\n",
    "\n",
    "news = Agent(name=\"News\",  role=\"Fetch and summarize current news\")\n",
    "wx   = Agent(name=\"Weather\", role=\"Provide concise forecasts\")\n",
    "\n",
    "team = Team(\n",
    "    name=\"News+Weather\",\n",
    "    members=[news, wx],\n",
    "    model=OpenAIChat(id=\"gpt-4o\"),\n",
    "    instructions=[\"Answer the user's request by delegating appropriately. Keep it brief.\"]\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6286532",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Running a Team\n",
    "\n",
    "Use `run()` for a single response or stream events for live updates.\n",
    "\n",
    "```python\n",
    "# Single response\n",
    "resp = team.run(\"What's happening in Tokyo and how's the weather?\")\n",
    "print(resp.content)\n",
    "\n",
    "# Streaming (yields TeamRunOutputEvent chunks)\n",
    "for ev in team.run(\"Same question, stream it\", stream=True, stream_events=True):\n",
    "    if getattr(ev, \"content\", None):\n",
    "        print(ev.content, end=\"\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783297f5",
   "metadata": {},
   "source": [
    "\n",
    "## 4. How Delegation Works\n",
    "\n",
    "The leader may reply directly or use the internal **delegate_task_to_members** tool to route tasks.  \n",
    "Members can run concurrently when using async execution and multi‑member delegation.\n",
    "\n",
    "```mermaid\n",
    "sequenceDiagram\n",
    "    participant U as User\n",
    "    participant L as Team Leader\n",
    "    participant N as News Agent\n",
    "    participant W as Weather Agent\n",
    "    U->>L: Ask: \"Latest news and 3‑day forecast for Tokyo\"\n",
    "    L->>N: Task: \"Summarize latest Tokyo news\"\n",
    "    L->>W: Task: \"Get concise 3‑day forecast\"\n",
    "    par Concurrent\n",
    "        N-->>L: News summary\n",
    "        W-->>L: Forecast\n",
    "    end\n",
    "    L-->>U: Synthesized answer\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624b3fa6",
   "metadata": {},
   "source": [
    "\n",
    "### Useful Delegation Knobs\n",
    "\n",
    "- **`respond_directly=True`** → leader returns member outputs as‑is (good for router patterns).\n",
    "- **`determine_input_for_members=False`** → user input is passed verbatim to selected members.\n",
    "- **`delegate_task_to_all_members=True`** → broadcast a task to every member at once (often with `arun`).\n",
    "\n",
    "```mermaid\n",
    "flowchart TB\n",
    "    A[User Input] --> L[Leader]\n",
    "    L -->|respond_directly| M1[Member A]\n",
    "    L -->|respond_directly| M2[Member B]\n",
    "    M1 --> O1[Direct Out]\n",
    "    M2 --> O2[Direct Out]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d942192e",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Debugging Teams\n",
    "\n",
    "Enable **debug mode** for verbose assembly of prompts, tool calls and metrics. Use streaming to observe events in real time.\n",
    "\n",
    "```python\n",
    "team = Team(\n",
    "    name=\"Debugger\",\n",
    "    members=[news, wx],\n",
    "    model=OpenAIChat(id=\"gpt-4o\"),\n",
    "    debug_mode=True,      # set debug_level=2 for even more detail\n",
    "    show_members_responses=True\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881fed66",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Conversation History\n",
    "\n",
    "With a database attached, the team can bring **recent turns** into context.\n",
    "\n",
    "```python\n",
    "from agno.db.sqlite import SqliteDb\n",
    "team = Team(\n",
    "    members=[news, wx],\n",
    "    model=OpenAIChat(id=\"gpt-4o\"),\n",
    "    db=SqliteDb(db_file=\"tmp/team.db\"),\n",
    "    add_history_to_context=True,\n",
    "    num_history_runs=3\n",
    ")\n",
    "```\n",
    "**Tip:** More history ⇒ bigger prompts. Start small and increase as needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3da0929",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Team Sessions\n",
    "\n",
    "Sessions group multiple runs for continuity. Use `user_id` and `session_id` to separate users and threads.\n",
    "\n",
    "```python\n",
    "team.run(\"Bonjour !\", user_id=\"u1\", session_id=\"s1\")\n",
    "team.run(\"Tell me a joke.\", user_id=\"u1\", session_id=\"s1\")\n",
    "team.run(\"Start fresh.\", user_id=\"u1\", session_id=\"s2\")\n",
    "```\n",
    "Optionally enable **session summaries** to condense long histories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c9731e",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Context Engineering (system message)\n",
    "\n",
    "The system message is composed from description, instructions, member info, and optional add‑ons (time, location, session summary, memories, etc.).\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    D[Description] --> S[(System Message)]\n",
    "    I[Instructions] --> S\n",
    "    M[Member Info & Tools] --> S\n",
    "    X[Add‑ons: time/location/memories/summary/state] --> S\n",
    "    S --> Model\n",
    "```\n",
    "**Common parameters:** `description`, `instructions`, `expected_output`, `markdown`, `add_datetime_to_context`, `add_member_tools_to_context`, `add_session_summary_to_context`, `add_memories_to_context`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413fba14",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Input & Output (structured when needed)\n",
    "\n",
    "Teams accept plain strings or **structured input** via Pydantic; outputs can also be validated.\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class StockReport(BaseModel):\n",
    "    symbol: str\n",
    "    company_name: str\n",
    "    analysis: str\n",
    "\n",
    "team = Team(\n",
    "    name=\"Stocks\",\n",
    "    members=[],\n",
    "    model=OpenAIChat(id=\"gpt-4o\"),\n",
    "    output_schema=StockReport,   # enforce structured output\n",
    ")\n",
    "result = team.run(\"Analyze NVDA in ~4 lines\").content\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0467e9",
   "metadata": {},
   "source": [
    "\n",
    "## 10. Dependencies (context injection)\n",
    "\n",
    "Provide callable dependencies to inject dynamic values (profile, time, retrieved docs) before each run.\n",
    "\n",
    "```python\n",
    "def get_profile():\n",
    "    return {\"name\": \"Ava\", \"interests\": [\"AI\", \"finance\"]}\n",
    "\n",
    "team = Team(\n",
    "    members=[news, wx],\n",
    "    model=OpenAIChat(id=\"gpt-4o\"),\n",
    "    dependencies={\"user_profile\": get_profile},\n",
    "    instructions=[\n",
    "        \"Personalize answers using {user_profile}. Keep responses concise.\"\n",
    "    ]\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9891db2c",
   "metadata": {},
   "source": [
    "\n",
    "## 11. Shared State (per‑session)\n",
    "\n",
    "A shared dictionary lives with the session. Tools receive it automatically so members can coordinate.\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    SS[(session_state)] --- A1[Member Tool]\n",
    "    SS --- A2[Team Tool]\n",
    "    U[User] --> Leader\n",
    "    Leader -->|updates| SS\n",
    "    A1 -->|reads/writes| SS\n",
    "    A2 -->|reads/writes| SS\n",
    "```\n",
    "```python\n",
    "def add_item(session_state, item: str):\n",
    "    if item not in session_state.setdefault(\"shopping_list\", []):\n",
    "        session_state[\"shopping_list\"].append(item)\n",
    "        return f\"Added {item}\"\n",
    "    return f\"{item} already present\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d9dda1",
   "metadata": {},
   "source": [
    "\n",
    "## 12. Storage (sessions & state persistence)\n",
    "\n",
    "Attach a database so sessions and state survive across requests.\n",
    "\n",
    "```python\n",
    "from agno.db.postgres import PostgresDb\n",
    "db = PostgresDb(db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\")\n",
    "team = Team(members=[news, wx], db=db)\n",
    "```\n",
    "\n",
    "**Session table (conceptual):**\n",
    "\n",
    "| Field | Type | Notes |\n",
    "|---|---|---|\n",
    "| `session_id` | `str` | Unique key |\n",
    "| `session_type` | `str` | Team/Agent/Workflow |\n",
    "| `agent_id` | `str` | If created by an Agent |\n",
    "| `team_id` | `str` | If created by a Team |\n",
    "| `workflow_id` | `str` | If created by a Workflow |\n",
    "| `user_id` | `str` | End‑user identifier |\n",
    "| `session_data` | `dict` | Arbitrary session payload |\n",
    "| `agent_data` / `team_data` / `workflow_data` | `dict` | Component‑specific |\n",
    "| `metadata` | `dict` | Custom tags |\n",
    "| `runs` | `list` | Run history |\n",
    "| `summary` | `dict` | Optional session summary |\n",
    "| `created_at` / `updated_at` | `int` | Timestamps |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac82913",
   "metadata": {},
   "source": [
    "\n",
    "## 13. Memory (long‑lived user facts)\n",
    "\n",
    "Enable user memories so the team can recall details across sessions.\n",
    "\n",
    "```python\n",
    "from agno.db.sqlite import SqliteDb\n",
    "team_with_memory = Team(\n",
    "    name=\"WithMemory\",\n",
    "    members=[news, wx],\n",
    "    db=SqliteDb(db_file=\"agno.db\"),\n",
    "    enable_user_memories=True,\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1ec4c7",
   "metadata": {},
   "source": [
    "\n",
    "## 14. Knowledge (RAG)\n",
    "\n",
    "Give the leader access to a knowledge base or search tools and include retrieved snippets in context.\n",
    "Key toggles include `add_knowledge_to_context=True` and toolkits (e.g., web search, DB readers).\n",
    "Use **agentic knowledge filters** to let the leader choose metadata filters when searching.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd79d03",
   "metadata": {},
   "source": [
    "\n",
    "## 15. Pre‑hooks & Post‑hooks (and Guardrails)\n",
    "\n",
    "**Pre‑hooks** run before the model — validate inputs, strip secrets, reshape data.  \n",
    "**Post‑hooks** run after the model — validate/transform output or enforce policies.  \n",
    "**Guardrails** are a common pre‑hook pattern to block disallowed content.\n",
    "\n",
    "```python\n",
    "# Tiny pre‑hook example (conceptual)\n",
    "from agno.exceptions import InputCheckError, CheckTrigger\n",
    "def block_empty(run_input, session, **_):\n",
    "    if not (run_input and getattr(run_input, \"input_content\", \"\").strip()):\n",
    "        raise InputCheckError(\"Empty input not allowed\", check_trigger=CheckTrigger.INPUT_NOT_ALLOWED)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b541005b",
   "metadata": {},
   "source": [
    "\n",
    "## 16. Metrics\n",
    "\n",
    "Every run exposes token/time metrics at message, member, team and session levels.\n",
    "\n",
    "```python\n",
    "out = team.run(\"Quick test\")\n",
    "print(\"Team totals:\", out.metrics)\n",
    "if out.messages:\n",
    "    for m in out.messages:\n",
    "        if getattr(m, \"metrics\", None):\n",
    "            print(\"Per‑message:\", m.metrics)\n",
    "```\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    Msg[Message Metrics] --> Agg[Team Aggregates]\n",
    "    Mem[Member Metrics] --> Agg\n",
    "    Agg --> Sess[Session Aggregates]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6bad19",
   "metadata": {},
   "source": [
    "\n",
    "## 17. Cancelling a Run\n",
    "\n",
    "Long operations can be cancelled by `team.cancel_run(run_id)` during streaming from another thread/process.\n",
    "Keep the `run_id` you receive as soon as streaming begins.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22871c82",
   "metadata": {},
   "source": [
    "\n",
    "## 18. Custom Loggers\n",
    "\n",
    "Swap Agno's default logger for your own (JSON, SIEM, etc.).\n",
    "\n",
    "```python\n",
    "from agno.utils.log import configure_agno_logging\n",
    "import logging\n",
    "\n",
    "custom = logging.getLogger(\"my_team_logger\")\n",
    "custom.setLevel(logging.INFO)\n",
    "configure_agno_logging(custom_team_logger=custom)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a821aa",
   "metadata": {},
   "source": [
    "\n",
    "## 19. Summary\n",
    "\n",
    "- Treat the Team Leader as a **router + synthesizer**.  \n",
    "- Keep builds **minimal** first; add state/history/memory only when needed.  \n",
    "- Prefer **structured I/O** for reliability in production.  \n",
    "- **Mermaid diagrams** here outline flows you can adapt to your architecture.  \n",
    "- Use **hooks, guardrails, metrics and logging** to make systems production‑ready.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4061da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional: lightweight smoke‑test to ensure Python imports resolve in your env.\n",
    "# Comment out if you haven't installed agno and providers yet.\n",
    "try:\n",
    "    import agno  # noqa: F401\n",
    "    print(\"Agno import OK.\")\n",
    "except Exception as e:\n",
    "    print(\"Agno not installed in this environment (that's fine for reading).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
